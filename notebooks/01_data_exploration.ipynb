{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db386fe7-35fe-4ca9-bd57-1ea51a9617c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m plt.rcParams[\u001b[33m'\u001b[39m\u001b[33mfigure.figsize\u001b[39m\u001b[33m'\u001b[39m] = (\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Configure pandas display\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mpd\u001b[49m.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_columns\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     19\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.width\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Libraries imported successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup and Imports\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìä Ready for data exploration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fab0e9-3476-4b01-bf16-d71cd226a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading data: name 'pd' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Load Data\n",
    "# ============================================================================\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '/app/data/raw/phelps_et_al_2016.xlsx'\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(data_path)\n",
    "    print(f\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Data file not found. Make sure your Excel file is in data/raw/\")\n",
    "    print(\"Current working directory contents:\")\n",
    "    print(list(Path('/app/data/raw/').glob('*')))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b742ac7-1e3c-48a3-a0e8-4b12584fb2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDATASET OVERVIEW\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows √ó \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.memory_usage(deep=\u001b[38;5;28;01mTrue\u001b[39;00m).sum()\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m1024\u001b[39m**\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Quick Data Overview\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"COLUMN NAMES\")\n",
    "print(\"=\" * 40)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\" * 40)\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049751ee-ded3-46fc-a3a9-27edb8b8e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: First Look at Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\" * 60)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LAST 5 ROWS\")\n",
    "print(\"=\" * 60)\n",
    "display(df.tail())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RANDOM SAMPLE\")\n",
    "print(\"=\" * 60)\n",
    "display(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a3117-6561-42bb-bac0-2ff29d27bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Data Quality Check\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Missing values\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': missing_data.index,\n",
    "    'Missing_Count': missing_data.values,\n",
    "    'Missing_Percentage': missing_percent.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "display(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "if missing_summary['Missing_Count'].sum() == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "\n",
    "# Duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicate_count}\")\n",
    "if duplicate_count > 0:\n",
    "    print(\"‚ö†Ô∏è Found duplicate rows - consider investigating\")\n",
    "else:\n",
    "    print(\"‚úÖ No duplicate rows found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128600b-012a-410c-b685-c52a78782bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Descriptive Statistics\n",
    "# ============================================================================\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VARIABLE TYPES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Numerical variables ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"Categorical variables ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "if numerical_cols:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"NUMERICAL STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    display(df[numerical_cols].describe())\n",
    "\n",
    "if categorical_cols:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CATEGORICAL STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "        print(f\"\\n--- {col} ---\")\n",
    "        print(f\"Unique values: {df[col].nunique()}\")\n",
    "        if df[col].nunique() <= 20:  # Only show value counts if not too many unique values\n",
    "            print(\"Value counts:\")\n",
    "            display(df[col].value_counts().head(10))\n",
    "        else:\n",
    "            print(\"Too many unique values to display (showing first 10 most common):\")\n",
    "            display(df[col].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a0b92-7f2d-47d8-839f-8563c2f60925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Visualizations - Distribution Plots\n",
    "# ============================================================================\n",
    "\n",
    "if numerical_cols:\n",
    "    print(\"Creating distribution plots for numerical variables...\")\n",
    "    \n",
    "    # Calculate grid size\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 5*n_rows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if len(numerical_cols) == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes if len(numerical_cols) > 1 else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        if i < len(axes):\n",
    "            # Create histogram with KDE\n",
    "            axes[i].hist(df[col].dropna(), bins=30, alpha=0.7, edgecolor='black', density=True)\n",
    "            \n",
    "            # Add KDE curve\n",
    "            from scipy import stats\n",
    "            try:\n",
    "                kde_data = df[col].dropna()\n",
    "                if len(kde_data) > 1:\n",
    "                    density = stats.gaussian_kde(kde_data)\n",
    "                    xs = np.linspace(kde_data.min(), kde_data.max(), 100)\n",
    "                    axes[i].plot(xs, density(xs), 'r-', linewidth=2)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            axes[i].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Density')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for j in range(len(numerical_cols), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a37a42-589b-4cfe-933d-f1ecfedd66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Box Plots for Outlier Detection\n",
    "# ============================================================================\n",
    "\n",
    "if numerical_cols:\n",
    "    print(\"Creating box plots for outlier detection...\")\n",
    "    \n",
    "    # Calculate grid size\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 5*n_rows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if len(numerical_cols) == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes if len(numerical_cols) > 1 else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        if i < len(axes):\n",
    "            bp = axes[i].boxplot(df[col].dropna(), patch_artist=True)\n",
    "            bp['boxes'][0].set_facecolor('lightblue')\n",
    "            bp['boxes'][0].set_alpha(0.7)\n",
    "            \n",
    "            axes[i].set_title(f'Box Plot: {col}', fontweight='bold')\n",
    "            axes[i].set_ylabel(col)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for j in range(len(numerical_cols), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e47a07-2928-414f-b933-b3b5d246e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: Correlation Analysis\n",
    "# ============================================================================\n",
    "\n",
    "if len(numerical_cols) > 1:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CORRELATION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    print(\"Correlation Matrix:\")\n",
    "    display(correlation_matrix.round(3))\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    \n",
    "    # Generate heatmap\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                cmap='coolwarm', \n",
    "                center=0, \n",
    "                square=True, \n",
    "                fmt='.2f',\n",
    "                cbar_kws={\"shrink\": .8})\n",
    "    \n",
    "    plt.title('Correlation Matrix Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated pairs\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.7:  # Threshold for high correlation\n",
    "                high_corr_pairs.append((\n",
    "                    correlation_matrix.columns[i], \n",
    "                    correlation_matrix.columns[j], \n",
    "                    corr_value\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        print(\"\\nüîç Highly Correlated Pairs (|r| > 0.7):\")\n",
    "        for col1, col2, corr in high_corr_pairs:\n",
    "            print(f\"  ‚Ä¢ {col1} ‚Üî {col2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No highly correlated pairs found (|r| > 0.7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb71e8-1f35-4c32-96a2-93fc8ccbb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: Categorical Data Visualization\n",
    "# ============================================================================\n",
    "\n",
    "if categorical_cols:\n",
    "    print(\"Creating visualizations for categorical variables...\")\n",
    "    \n",
    "    # Show first 3 categorical columns\n",
    "    for col in categorical_cols[:3]:\n",
    "        if df[col].nunique() <= 20:  # Only plot if not too many categories\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Bar plot\n",
    "            value_counts = df[col].value_counts()\n",
    "            value_counts.plot(kind='bar', ax=ax1, color='skyblue', edgecolor='black')\n",
    "            ax1.set_title(f'Distribution of {col}', fontweight='bold')\n",
    "            ax1.set_xlabel(col)\n",
    "            ax1.set_ylabel('Count')\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Pie chart (only if <= 10 categories)\n",
    "            if len(value_counts) <= 10:\n",
    "                value_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', startangle=90)\n",
    "                ax2.set_title(f'Proportion of {col}', fontweight='bold')\n",
    "                ax2.set_ylabel('')\n",
    "            else:\n",
    "                ax2.text(0.5, 0.5, f'Too many categories\\nfor pie chart\\n({len(value_counts)} unique values)', \n",
    "                        ha='center', va='center', transform=ax2.transAxes)\n",
    "                ax2.set_xlim(0, 1)\n",
    "                ax2.set_ylim(0, 1)\n",
    "                ax2.set_xticks([])\n",
    "                ax2.set_yticks([])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fc911-1bba-4062-bbeb-c909c3c32dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: AI Analysis (if Ollama is available)\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    # Test Ollama integration\n",
    "    from src.ollama_helper import setup_ollama\n",
    "    \n",
    "    print(\"ü§ñ Connecting to AI assistant...\")\n",
    "    ai = setup_ollama(\"llama2\")\n",
    "    \n",
    "    # Create dataset summary for AI\n",
    "    summary = f\"\"\"\n",
    "    Dataset Analysis Summary:\n",
    "    - Shape: {df.shape[0]} rows, {df.shape[1]} columns\n",
    "    - Numerical variables: {len(numerical_cols)} ({', '.join(numerical_cols[:5])})\n",
    "    - Categorical variables: {len(categorical_cols)} ({', '.join(categorical_cols[:3])})\n",
    "    - Missing values: {df.isnull().sum().sum()} total\n",
    "    - Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\n",
    "    \n",
    "    This appears to be research data from Phelps et al. 2016.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üß† Getting AI analysis suggestions...\")\n",
    "    response = ai.ask(f\"\"\"\n",
    "    Based on this dataset summary, what are the most important next steps for analysis?\n",
    "    \n",
    "    {summary}\n",
    "    \n",
    "    Please provide 3-5 specific, actionable recommendations for data analysis.\n",
    "    \"\"\")\n",
    "    \n",
    "    if response and response != \"Error: Could not get response\":\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ü§ñ AI ANALYSIS SUGGESTIONS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è AI assistant not available - continuing without AI suggestions\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Ollama helper not found - run this in Docker for AI features\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è AI integration error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5fcb1-32a7-4ebb-acd8-05c77275ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: Summary and Next Steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"‚úÖ Dataset successfully loaded and explored\")\n",
    "print(f\"üìà Found {len(numerical_cols)} numerical and {len(categorical_cols)} categorical variables\")\n",
    "print(f\"üîç Data quality: {df.isnull().sum().sum()} missing values, {df.duplicated().sum()} duplicates\")\n",
    "\n",
    "if len(numerical_cols) > 1:\n",
    "    high_corr_count = len([1 for i in range(len(correlation_matrix.columns)) \n",
    "                          for j in range(i+1, len(correlation_matrix.columns)) \n",
    "                          if abs(correlation_matrix.iloc[i, j]) > 0.7])\n",
    "    print(f\"üîó Found {high_corr_count} highly correlated variable pairs\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"üéØ RECOMMENDED NEXT STEPS\")\n",
    "print(\"=\" * 40)\n",
    "print(\"1. üßπ Handle missing values and outliers\")\n",
    "print(\"2. üî¨ Perform statistical tests and hypothesis testing\") \n",
    "print(\"3. ü§ñ Use AI assistant for advanced analysis suggestions\")\n",
    "print(\"4. üìä Create publication-ready visualizations\")\n",
    "print(\"5. üîç Investigate interesting patterns found in the data\")\n",
    "print(\"6. üìù Document findings and create analysis report\")\n",
    "\n",
    "print(f\"\\nüéâ Data exploration complete! Ready for advanced analysis.\")\n",
    "print(f\"üí° Tip: Use the AI assistant to get specific analysis recommendations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc2278-7e2b-492a-91ee-93828d049592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: Quick Data Access Functions\n",
    "# ============================================================================\n",
    "\n",
    "def quick_summary():\n",
    "    \"\"\"Quick function to show dataset summary\"\"\"\n",
    "    print(f\"Dataset: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"Numerical: {len(numerical_cols)} variables\")\n",
    "    print(f\"Categorical: {len(categorical_cols)} variables\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    return df.info()\n",
    "\n",
    "def show_correlations(threshold=0.5):\n",
    "    \"\"\"Show correlations above threshold\"\"\"\n",
    "    if len(numerical_cols) > 1:\n",
    "        corr = df[numerical_cols].corr()\n",
    "        high_corr = []\n",
    "        for i in range(len(corr.columns)):\n",
    "            for j in range(i+1, len(corr.columns)):\n",
    "                if abs(corr.iloc[i, j]) > threshold:\n",
    "                    high_corr.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "        \n",
    "        for col1, col2, corr_val in high_corr:\n",
    "            print(f\"{col1} ‚Üî {col2}: {corr_val:.3f}\")\n",
    "    else:\n",
    "        print(\"Need at least 2 numerical columns for correlation analysis\")\n",
    "\n",
    "def plot_variable(column_name):\n",
    "    \"\"\"Quick plot for any variable\"\"\"\n",
    "    if column_name in numerical_cols:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Histogram\n",
    "        df[column_name].hist(bins=30, ax=ax1, alpha=0.7, edgecolor='black')\n",
    "        ax1.set_title(f'Distribution of {column_name}')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Box plot\n",
    "        df[column_name].plot(kind='box', ax=ax2)\n",
    "        ax2.set_title(f'Box Plot of {column_name}')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary stats\n",
    "        print(f\"\\nSummary for {column_name}:\")\n",
    "        print(df[column_name].describe())\n",
    "        \n",
    "    elif column_name in categorical_cols:\n",
    "        # Bar plot for categorical\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        df[column_name].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "        plt.title(f'Distribution of {column_name}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nValue counts for {column_name}:\")\n",
    "        print(df[column_name].value_counts())\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' not found in dataset\")\n",
    "\n",
    "print(\"‚úÖ Helper functions defined:\")\n",
    "print(\"  ‚Ä¢ quick_summary() - Show dataset overview\")\n",
    "print(\"  ‚Ä¢ show_correlations(threshold=0.5) - Show correlated variables\") \n",
    "print(\"  ‚Ä¢ plot_variable('column_name') - Quick plot any variable\")\n",
    "print(\"\\nExample: plot_variable('your_column_name')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
